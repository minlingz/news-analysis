{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json, os, sys\n",
    "import os\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(chunk, client, model=\"gpt-4o\", n=1):\n",
    "    prompt = f\"\"\"\n",
    "Role: You are an expert in news analysis, skilled at creating multiple-choice questions that effectively differentiate topics between articles.\n",
    "\n",
    "Task: Generate unique and comprehensive multiple-choice questions based on the provided article summaries. These questions should:\n",
    "\n",
    "\t•\tHelp to distinguish the topics covered in the articles.\n",
    "\t•\tBe based on the content of the summaries provided.\n",
    "\t•\tBe applicable to all articles, rather than specific to any single article.\n",
    "\t•\tBe comprehensive, covering a wide range of summaries.\n",
    "\t•\tBe unique, avoiding repetition.\n",
    "\t•\tBe objective, ensuring that answers are fact-based and not open to interpretation.\n",
    "\t•\tInclude “None of the above” as one of the options for each question.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "\t1.\tQuestion Format: Each question should be concise, clear, and directly related to the content of the summaries.\n",
    "\t2.\tAnswer Options: Provide five options for each question, with one correct answer and “None of the above” as one of the options.\n",
    "\t3.\tTopic Differentiation: Ensure that the questions are designed to highlight differences in topics.\n",
    "\n",
    "Example Structure:\n",
    "\n",
    "\t1.\tWhat was done?\n",
    "\t•\tA. The Chinese coast guard seized one of four food packs dropped by a Philippine military plane for Filipino navy personnel at a territorial outpost. After discovering the package contained food, they dumped it into the sea.\n",
    "\t•\tB. Philippine soldiers were reported to have pointed guns at Chinese coast guard personnel during a resupply mission to the grounded Sierra Madre ship. The Chinese coast guard responded to the resupply operation, which included food drops, by observing armed Philippine soldiers on the ship’s deck.\n",
    "\t•\tC. Turkish Foreign Minister Hakan Fidan began a trip to China and expressed priorities to support Hamas against Israel and increase trade with China, without condemning the Uyghur genocide.\n",
    "\t•\tD. The Philippines is collaborating with the United States and Japan to ensure the West Philippine Sea (WPS) remains free and safe amid tensions with Chinese maritime forces.\n",
    "\t•\tE. None of the above\n",
    "    \n",
    "Questions that need multiple choice answers to be generated (Generate your own unique topical questions when needed based on the provided summaries.):\n",
    "\n",
    "\t1. What is the main theme of the article? \n",
    "\t2. What are the primary keywords or phrases in this article? \n",
    "\t3. What event or issue is the article centered around?\n",
    "\t4. Which region or country is primarily discussed in the article?\n",
    "\t5. Who is most affected by the issues discussed in the article?\n",
    "\t6. What type of sources does the article cite?\n",
    "\t\n",
    "Output: Provide a list of multiple-choice questions and answers following the above structure. Each question should effectively differentiate between the topics of the provided article summaries.\n",
    "\n",
    "{n} Summaries: \n",
    "\t{chunk}\n",
    "\n",
    "\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model, messages=messages, temperature=0\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "        return content\n",
    "    except Exception as e:  # if the model fails to return a response\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Sorry, error from GPT.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batches(input_file, output_file, client, model, label):\n",
    "    # Read the article summaries from the input JSON file\n",
    "    with open(input_file, \"r\") as f:\n",
    "        articles = json.load(f)\n",
    "\n",
    "    # if i in the label extract the summaries from articles[i]\n",
    "    article_summaries = [article[\"summary\"] for article in articles]\n",
    "    # get the article body with the label_a_index list\n",
    "    batch = [article_summaries[i] for i in label]\n",
    "\n",
    "    random.shuffle(batch)\n",
    "    responses = []\n",
    "\n",
    "    chunk = json.dumps(batch)  # Convert the batch to a JSON string\n",
    "\n",
    "    questions = generate_questions(chunk, client, model=model, n=len(batch))\n",
    "    responses.append(\n",
    "        {\n",
    "            \"questions\": questions,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Write the generated questions to the output JSON file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(responses, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the label file\n",
    "labels = pd.read_csv(\"labels_4o.csv\", header=None, names=[\"label\"])\n",
    "# get the label index if labe is 1\n",
    "# label = list(labels[labels[\"label\"] != 1].index)\n",
    "label = list(range(0, 200))\n",
    "random.shuffle(label)\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"combined_Russo_Ukrainian_War.json\"\n",
    "output_file = \"output_questions_test.json\"\n",
    "\n",
    "# Assuming you have your OpenAI API client initialized as `client`\n",
    "process_batches(input_file, output_file, client, model=\"gpt-4o\", label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions(batch_questions):\n",
    "    questions = {}\n",
    "    q_count = 1\n",
    "    for batch in batch_questions:\n",
    "        batch_qs = batch[\"questions\"].split(\"\\n\\n\")\n",
    "        for q in batch_qs:\n",
    "            match = re.match(\n",
    "                r\"\\d+\\. (.+?)\\n\\s+- A\\. (.+?)\\n\\s+- B\\. (.+?)\\n\\s+- C\\. (.+?)\\n\\s+- D\\. (.+?)\\n\\s+- E\\. (.+?)$\",\n",
    "                q.strip(),\n",
    "                re.DOTALL,\n",
    "            )\n",
    "            if match:\n",
    "                question = match.group(1).strip()\n",
    "                choices = {\n",
    "                    \"A\": match.group(2).strip(),\n",
    "                    \"B\": match.group(3).strip(),\n",
    "                    \"C\": match.group(4).strip(),\n",
    "                    \"D\": match.group(5).strip(),\n",
    "                    \"E\": match.group(6).strip(),\n",
    "                }\n",
    "                if question not in questions:\n",
    "                    questions[question] = choices\n",
    "    return questions\n",
    "\n",
    "\n",
    "def convert_to_json2_format(unique_questions):\n",
    "    formatted_questions = {}\n",
    "    q_num = 1\n",
    "    for question, choices in unique_questions.items():\n",
    "        formatted_questions[f\"Q{q_num}\"] = {\"question\": question, \"choices\": choices}\n",
    "        q_num += 1\n",
    "    return formatted_questions\n",
    "\n",
    "\n",
    "def process_json(input_json):\n",
    "    unique_questions = extract_questions(input_json)\n",
    "    return convert_to_json2_format(unique_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON 1\n",
    "with open(\"output_questions_test.json\", \"r\") as f:\n",
    "    json1 = json.load(f)\n",
    "\n",
    "# Process JSON 1 to get JSON 2 format\n",
    "json2_format = process_json(json1)\n",
    "\n",
    "# Save the result to a new JSON file\n",
    "with open(\"formated_output_questions_v3.json\", \"w\") as f:\n",
    "    json.dump(json2_format, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
